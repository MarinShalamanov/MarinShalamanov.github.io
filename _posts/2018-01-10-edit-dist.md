---
layout:     post
title:      Approximate String Matching and Suffix Arrays
date:       2018-01-10
summary:    A O(kn + nlgn) algorithm.
categories: algorithms informatics 
---

## Introduction

In this post we'll disscuss and implement a $$O(kn + n\log(n))$$ algorithm for approximate string matching, where $$n$$ = length of pattern + text and $$k$$ = number of edits. We'll discuss a $$O(kn)$$ solution and possible generalizations.

Full source code can be found [here](https://github.com/MarinShalamanov/ApproximateStringMatching/blob/master/diagonal_transitions.cc).

## Edit Distance

Edit distance $$edit(s_1, s_2)$$  between two strings $$s_1$$ and $$s_2$$ is the minimum number of edit operations that needs to be applied to $$s_1$$ to obtain $$s_2$$.
Edit operations are:
- insertion of a symbol
- deletion of a symbol
- replacement of a symbol



For example the edit distance between `havana` and `banana` is two because we can transform `havana` into `banana` with a minimum of 2 edit operations:
`havana` -> `bavana` -> `banana`.

## Approximate String Matching

Given a pattern and text we want to find all substrings of the text which are edit distance at most $$k$$ from the pattern. More formally we want to find

$$ \{ m | m \in Inf(text) \& edit(m, pattern) \le k \} $$

where $$Inf(text)$$ is the set of all substrings of $$text$$.

This problem can be solved using dynamic programming. Suppose $$D(i, j)$$ is the minimal number of edit operation between $$p[:i]$$ and any suffix of $$t[:j]$$. Then:

$$ D(i, j) = \begin{cases} 
      i & j = 0 \\
      0 & i = 0 \\
      \min(D(i-1, j), D(i, j-1), D(i-1, j-1)+e_{i,j}) & otherwise
   \end{cases}
$$

where $$ e_{i,j} = \begin{cases} 
      0 & p[i] = t[i] \\
      1 & otherwise
   \end{cases}
$$


```cpp
int fullDynProg(const std::string& p, const std::string& t, size_t k)
{
  const int m = p.length(), n = t.length();
  if (k >= m) return 0;
  vector<int> previous(m + 1);
  vector<int> current(m + 1);
  for (int i = 0; i <= m; i++)
      previous[i] = i;
  int matches = 0;

  for (int i = 0; i < n; i++) {
    current[0] = 0;
    for (int j = 1; j <= m; j++) {
      current[j] = min(current[j - 1] + 1,
        previous[j] + 1,
        previous[j - 1] + 1 - (t[i] == p[j - 1]));
    }
    // matching substring found at position i+1
    if (current[m] <= k) ++matches; 
    swap(previous, current);
  }
  return matches;
}
```
Source credit: [Andrey Drenski](https://github.com/Andreshk/ApproximateStringMatching/blob/master/Source.cpp)

## Diagonal Transitions

In the table D from the dynamic programming solution all diagonals are monotonically increasing and when they are increasing they are increasing only by 1. More formally $$ D(i,j) \in \{ D(i-1, j-1), D(i-1, j-1)-1 \}$$. Following this idea can store only the points there the value on the diagonals change. The following algorithm (algorithm MN2 from [2]) uses this idea:

```cpp
int ComputeEditDistance(const string& p,
                        const string& t, const int k) {
  const int m = p.length(), n = t.length();
  if (k >= p.length()) return 0;

  const int table_w = n - m + k + 3;
  const int table_h = k + 2;
  int col, d;
  vector<int> preprevious(table_h, -2);
  vector<int> previous(table_h, -1);
  vector<int> current(table_h);

  int matches = 0;

  for (int j = 2; j < table_w; j++)
  {
    current[0] = j - 2;
    for (int i = 1; i < table_h; i++)
    {
      col = max(preprevious[i - 1] + 1,
                previous[i - 1] + 1,
                current[i - 1]);
      d = j - i - 1;
      while (col < n && col - d < m && p[col - d] == t[col])
        col++;
      current[i] = min(col, m + d);
    }
    if (current[k + 1] == m + j - k - 2) {
      // matching substring found at position current[k + 1]
      matches++; 
    }
    swap(preprevious, previous);
    swap(previous, current);
  }
  return matches;
}
```

The complexity of this proceedure is O(nm) as discussed in [2].

## Suffix Tree

The bottleneck of the abovementioned algorithm comes from the following loop
```cpp
while (col < n && col - d < m && p[col - d] == t[col])
  col++;
```

This loop finds the largest common prefix of $$p[col-d:], t[col:]$$. If we manage to do this for $$O(1)$$ time, the overal complexity will become $$O(kn)$$.

In other words we want to find the largest common prefix (LCP) of arbitrary suffixes of $$p$$ and $$t$$. This problem is equivalent to the problem of finding LCP of two suffixes of a single string (then we'll take this string to be $$pattern \circ text$$). We'll use the suffix tree of that string to solve the problem. 

Let's take for example the string `abbabbab` and take a look to it's suffix tree (which is a [trie](https://en.wikipedia.org/wiki/Trie) of all of its suffixes).

![desk](https://upload.wikimedia.org/wikipedia/de/7/7e/Suffixbaum.png)

Image credit: Von Fabian Steeg (Benutzer:Fabian Steeg) mit GraphViz - selbst erstellt, CC-by-sa 2.0/de, https://de.wikipedia.org/w/index.php?curid=1319293

Each suffix corresponds to path from the root to a leaf. The longest common prefix of two suffixes corresponds to the common part of the paths of the suffixes. Thus the problem of finding the LCP of two suffixes is equivalent to the problem of finding the lowest common ancestor (LCA) of two leaves in the suffix tree. Unfortunately constructing and working with the suffix tree is rather slow. In fact, initially this algorithm had been considered impractical because of hidden big constants in the use of suffix tree (see [2]). We'll apply a standart technique (which is unknown during the time of publishing [1]) which will replace the suffix tree with two arrays.

## Suffix Array + LCP Array

Let's consider a fixed string with length $$n$$. We'll denote the suffix which starts at position $$i$$ with $$s_i$$. 
The [suffix array](https://en.wikipedia.org/wiki/Suffix_array) $$SA[]$$ contains a premutation of the numbers $$0, 1, \dots n-1$$ such that $$s_{SA[0]}, s_{SA[1]}, \dots s_{SA[n-1]}$$ is lexicographically  sorted. In other words the suffix array contains the sorted suffixes.

The [LCP Array](https://en.wikipedia.org/wiki/LCP_array) LCP[i] contains the longest common prefix of the i-th and (i+1)-th suffix in the lex order.

Suffix array and the LCP array are enough to represent a suffix tree. In fact, given only a Suffix array and LCP array one can reconstruct the suffix tree. The suffix array gives us the order of the leaves of the tree and the LCP array gives us information about the inner structure of the tree. 

So far we transformed our initial problem to the problem of finding LCA in a tree. Now we'll make one final tranformation to RMQ, which we'll solve for O(1) time. Suppose we've already computed the LCA array and we search for LCA for the i-th and the j-th leaf. The following observation reduces the problem to RMQ:

$$ LCA(i, j) = min \{ LCA(i, i+1), LCA(i+1, i+2), \dots LCA(j-1, j)\} = \min_{i \le k < j} LCA[k]$$


Computing the Suffix array we do with the following method in time $$O(n.\log(n))$$. See [3] for details.
```cpp
int suffix_array_pos[MAX_LOG_N][MAX_N];
int suffix_array[MAX_N];
void ComputeSuffixArray(const string& p, const string& t) {
  len_pattern = p.length();
  len_text = t.length();

  const string str = p + t;
  cout << str << endl;
  n = str.length();

  for (int i = 0; i < n; i++) {
    suffix_array_pos[0][i] = str[i] - 'a';
  }

  vector< tuple<int, int, int> > l (n);
  const int log_n = CeilLog(n);
  for (int k = 1, len = 1; k <= log_n; k++, len *= 2) {
    for (int i = 0; i < n; i++) {
      l[i] = make_tuple(suffix_array_pos[k-1][i], 
                        suffix_array_pos[k-1][i+len], 
                        i);
    }
    sort(l.begin(), l.end());
    for (int i = 0; i < n; i++) {
      const bool equal_to_last = i > 0 &&
        get<0>(l[i-1]) == get<0>(l[i]) &&
        get<1>(l[i-1]) == get<1>(l[i]);
      const int pos = get<2>(l[i]);
      if (equal_to_last) {
        const int pos_last = get<2>(l[i-1]);
        suffix_array_pos[k][pos] = suffix_array_pos[k][pos_last];
      } else {
        suffix_array_pos[k][pos] = i;
      }
    }
  }

  for (int i = 0; i < n; i++) {
    suffix_array[suffix_array_pos[log_n][i]] = i;
  }
}
```

## RMQ
Finally we need to compute $$\min_{i \le k < j} LCA[k]$$ in constant time. We'll preprocess array $$LCAMIN$$ such that

$$LCAMIN[k][i] = \min_{i \le j < i+2^k} LCA[j] $$

This preprocessing can be done in time $$O(n.\log(n))$$ by following this:

$$ LCAMIN[k][i] = \begin{cases} 
      LCA[i] & k = 0 \\
      \min(LCAMIN[k-1][i], LCAMIN[k-1][i+2^{k-1}]) & k > 0
   \end{cases}
  $$



```cpp
void PreprocessLCP() {
  const int log_n = CeilLog(n);

  for (int i = 0; i+1 < n; i++) {
    lcp_mins[0][i] =
      ComputeLongestCommonPrefixInConcat(suffix_array[i], 
                                         suffix_array[i+1]);
  }
  for (int k = 1; k <= log_n; k++) {
    for (int i = 0; i+1 < n; i++) {
      const int next_half_start = i + (1<<(k-1));
      lcp_mins[k][i] = lcp_mins[k-1][i];

      if (next_half_start+1 < n) {
        lcp_mins[k][i] =
          min(lcp_mins[k-1][i], lcp_mins[k-1][next_half_start]);
      }
    }
  }
}
```


Now we can do the constant computation by:

$$\min_{i \le k < j} LCA[k] = \min ( LCA[l][i], LCA[l][j-2^l] ) $$

where $$ l =  \lfloor log(j-i) \rfloor $$.


```cpp
int GetLongestCommonPrefixInConcat(int i, int j) {
  const int log_n = CeilLog(n);
  int suff_i = suffix_array_pos[log_n][i];
  int suff_j = suffix_array_pos[log_n][j];
  if (suff_j < suff_i) swap(suff_i, suff_j);
  const int len = suff_j-suff_i;
  const int log_len = FloorLog(len);
  const int lcp = min(lcp_mins[log_len][suff_i], 
                      lcp_mins[log_len][suff_j-(1<<log_len)]);
  return lcp;
}

```

Finally we can replace 

```cpp
while (col < n && col - d < m && p[col - d] == t[col])
  col++;
```

with 

```cpp
col += GetLongestCommonPrefix(col - d, col);
```
## Improving to O(kn)

The suffix array construction can be done in $$O(n)$$ time instead of $$O(n.log(n))$$. The LCA problem can be solved with $$O(n)$$ preprocessing and $$O(1)$$ query using [5]. This will reduce the total preprocessing time to $$O(n)$$ and the total complexity to $$O(kn)$$. 


## Generalizations


## References 

[1] Landau G. M., Vishkin U. Fast parallel and serial approcimate string matching. Journal of Algorithms 10, 1989

[2] Galil Z, Park K. An improved algorithm for approximate string matching. SIAM Journal on Computing. 1990 Dec;19(6):989-99.

[3] Vladu A, Negruşeri C. Suffix arrays – a programming contest approach. [link](http://web.stanford.edu/class/cs97si/suffix-array.pdf)

[4] Nong, Ge; Zhang, Sen; Chan, Wai Hong (2009). Linear Suffix Array Construction by Almost Pure Induced-Sorting. 2009 Data Compression Conference. p. 193. doi:10.1109/DCC.2009.42. ISBN 978-0-7695-3592-0.

[5] Schieber, Baruch; Vishkin, Uzi (1988), "On finding lowest common ancestors: simplification and parallelization", SIAM Journal on Computing, 17 (6): 1253–1262
